20220326_201928_data: example of diverging.
20220326_211358_data: example of converging, but too short. If episodes are increased, it diverges.
20220327_125930_data: one of the first two complete trainings, this diverges.
20220327_164541_data: one of the first two complete trainings, this does not seem to learn much.
20220328_141136_data: shorter, complete training. First example of TTS plateau, i.e., stops learning.
20220328_162625_data: similar to previous, just with larger bounds. Plateaus the same.
20220329_122635_data: nice result, but what if it is improving just because of noise?
20220329_154411_data: longest results, but plateaus...

20220331_114340_data: exploring new scenarios (40% mismatch)
20220331_130431_data: lr is large (0.1), it breaks
20220331_141346_data: decreased lr
20220331_154744_data: comparing to previous but without noise. Seems noise is only making it look like it is learning
20220331_201637_data: using one cycle lr does not seem to have improved things

20220404_172122_data: tried increasing demands, no qp update, but iterates diverge at some point

20220405_194203_data: back to 40% scenario, now with affine initial cost. Seems decent                                      <---
20220407_094808_data: 50 episodes version with small noise                                                                  <---

20220413_152733_data: just moved ramp from 3rd to 2nd link
20220413_173020_data: changed seed from 42 to 69, behaviour is comparable luckly